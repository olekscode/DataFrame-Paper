\documentclass{article}

\usepackage[T1]{fontenc} %%%key to get copy and paste for the code!
\usepackage[utf8]{inputenc} %%% to support copy and paste with accents for frnehc stuff
\usepackage{times}
\usepackage[scaled=0.85]{helvet}
\usepackage{graphicx}
\usepackage{ifthen}
\usepackage{xspace}
\usepackage{alltt}
\usepackage{latexsym}
\usepackage{url}            
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{stmaryrd}
\usepackage{enumerate}
\usepackage{cite}
\usepackage[pdftex,colorlinks=true,pdfstartview=FitV,linkcolor=blue,citecolor=blue,urlcolor=blue]{hyperref}
\usepackage{xspace}

\usepackage{float}
% \usepackage{xcolor}
% \usepackage{listings}
% \usepackage{highlight}
\usepackage{multicol}

\usepackage
[
  left=20mm,
  right=20mm,
  top=30mm,
  bottom=30mm,
  bindingoffset=10mm
  % use vmargin=2cm to make vertical margins equal to 2cm.
  % use hmargin=3cm to make horizontal margins equal to 3cm.
  % use margin=3cm to make all margins  equal to 3cm.
] {geometry}

\input{macros}

\setlength\parindent{0pt}

\title{Towards Exploratory Data Analysis for Pharo}
% \author{
%   % 1st. author
%   \alignauthor
%   Oleksandr Zaytsev\\
% %     \affaddr{This is Author School Name}\\
%   % 2nd. author
%     \email{olk.zaytsev@gmail.com}
%   \alignauthor
%   Nick Papoylias
% %     \affaddr{This is Author School Name}\\
%     \texttt{npapoylias@gmail.com}
%   % 3rd. author
%   \alignauthor
%   Serge Stinckwich
% %     \affaddr{This is Author School Name}\\
%     \texttt{serge.stinckwich@gmail.com}
% }

\author{
  Oleksandr Zaytsev\\
    \texttt{olk.zaytsev@gmail.com}}

\date{}

\begin{document}
\maketitle

%\title{Title that Describes the Contribution that Solves a Problem}
%\author{Oleksandr Zaytsev}
%\date{\today}
%\maketitle

\begin{abstract}
% In this context...
% We consider this problem P...
% P is a problem because...
% We propose this solution...
% Our solution solves P in such and such way.

\noindent Data analysis and visualizations techniques (such as split-apply-combine) make extensive use of associative tabular data-structures that are cumbersome to use with common aggregation APIs (for arrays, lists or dictionaries). In these cases a fluent API for querying associative tabular data (like the ones provided by Pandas, Mathematica or LINQ) is more appropriate for dynamic environments such as Pharo. Despite the fact that many important tools for data-analysis are already implemented in PolyMath, we are still missing. 

\noindent The simplicity and power of Smalltalk combined with a live environment provided by Pharo creates a perfect environment for data analysis. The advanced debugging and inspecting tools together with the library for agile visualizations allow us to communicate and play with every object in our system. This includes all the logical components of both data and the algorithm. Provided the proper tools and open source libraries for machine learning, statistics, and optimization, Pharo can become both powerful tool for professional data analysts, and a simple environment for everyone who wants to play with a data set. Many important tools and algorithms are already implemented in PolyMath. But the essential part of data analysis toolkit is missing - the specialized data structures for tabular data sets with a simple and powerful API for summarizing, cleaning, and manipulating the data. In this paper I introduce \texttt{DataFrame} and \texttt{DataSeries} - the new collections specifically designed for working with structured data. I demonstrate how these tools can be used for descriptive statistics and the exploratory data analysis - the critical first step of data analysis which allows us to get the summary of a data set, detect mistakes, determine the relations, and select the appropriate model for further confirmatory analysis.
\end{abstract}

\begin{multicols}{2}
\section{Introduction}
\label{sec:intro}

% Context
%
% Problem
%
% Known tracks for \sd{solutions}
% 	here you want to show that you are not an idiot not knowing what have been around
%
% What our solution is \ct{Set} and \ct{OrderedCollection} (so that the reader knows where the paper is going)
%
% Contribution of the paper

All pictures in this paper are the built-in DataFrame visualizations that are created with Roassal2 and can be reproduced by following the steps in section \

\paragraph{Paper structure} In the first section I provide a brief introduction into the explanatory data analysis. What is it good for? How to do it right? I will also provide you with all the basic knowledge about statistics and data analysis, such as statistical variable, types of variables etc. In the second section I briefly describe the DataFrame - new data structure for data analysis. In the following section I will give a step-by-step example of how to perform EDA on the well-known Iris data set.




% \section{Problem Description}
% \label{sec:problem}

% Context, exposed with the \textbf{most precise terms possible} (don't open
% unwanted doors for the reader)
%
% Probably set the vocabulary before to cut any misinterpretation
%
% Constraints that influenced the solution (because the solution is not
% universal) \emph{e.g.} our requirements for a solution, possibly not all
% satisfied. They should be sound and believable. Analysis of the criteria.
% Imagine that you are another guy having this problem do the constraint
% matches yours so that you could apply the solution
%
% Problem
%
% Factual solution tracks, to position...
% Our solution in a nutshell.

\section{Exploratory Data Analysis}
\label{sec:eda}
\textbf{Exploratory data analysis (EDA)} is an approach to analyzing data sets to summarize their main characteristics. It allows us to make some sense of the data by visualizing it and exploring its statistical properties. According to Howard J. Seltmanan, any method of looking at data that does not include formal statistical modeling and inference falls under the term exploratory data analysis\cite{Seltman}. It is an important first step of data analysis which helps us to select the model that we will be fitting to the data during the following steps of confirmatory data analysis.

EDA can be particularly useful for uncovering underlying structure of a dataset, detecting outliers and anomalies, determining relationships among the explanatory variables, assessing the direction and rough size of relationships between explanatory and outcome variables, and selecting applopriate models for further analysis\cite{eStats}.

By the number of variables and the ... the techniques of exploratory data analysis can be cross-classified into four types: univariate graphical, univariate non-graphical, multivariate graphical, and multivariate non-graphical.

\section{DataSeries and DataFrame}
\label{sec:dataframe}
DataSeries and DataFrame are the high-level data structures that make data analysis in Pharo fast and easy.
\cite{McKinney}

DataFrame can be loaded into a Pharo image with the following Metacello script:
\begin{code}{}
Metacello new
    baseline: 'DataFrame';
    repository: 'github://PolyMathOrg/DataFrame';
    load.
\end{code}
\textbf{DataSeries} is an ordered collection that combines the properties of both Dictionary and Array, together with some extra functionality. It has a name and contains an array of data mapped to the corresponding array of keys (index values).

The easiest way of creating a series is by converting it from an array. 
\begin{code}{}
series := #(a b c) asDataSeries.
\end{code}
The keys will be automatically set to the numeric sequence which can be described as an interval (1 to: n), where n is the size of array, and the name will remain empty. Both name and the keys of a DataSeries can be changed later:
\begin{code}{}
series name: 'letters'.
series keys: #(a1 a2 a3).
\end{code}
\textbf{DataFrame} is a tabular data structure and an ordered collection of columns. It works like a spreadsheet or a relational database with one row per subject and one column for each subject identifier, outcome variable, and explanatory variable. DataFrame has both row and column indices which can be changed if needed. The important feature of a DataFrame is that whenever we ask for a specific row or column, it responds with a DataSeries object that preserves the same indexing.

A simple DataFrame can be created from an array of rows or columns.
\begin{code}{}
df := DataFrame rows: #((John 25 true)(Jane 21 false)).
df := DataFrame columns: #((John Jane)(25 21)(true false)).
\end{code}
Those two line produce exactly the same DataFrame. Once again, the names (key values) of both rows and columns were not explicitly specified, so by default they will set to numerical indices: \#(1 2) for rows and \#(1 2 3) for columns. These names can be changed later:
\begin{code}{}
df columnNames: #(Name Age IsMarried).
\end{code}
%\section{Proposed Solution}%
\section{Exploring Iris Data Set}
\label{sec:contribution}
%
% Free form, variable number of sections, technical details.
%
% But in general do not mix solution and discussions/possible variation
% let that for discussion

We can start by loading iris data set from a CSV file.
\begin{code}{}
data := DataFrame fromCsv: '/path/to/iris.csv'.
\end{code}
DataFrame comes with a built-in collection of data sets that are widely used as examples for data analysis and machine learning problems. Iris is among them, so an alternative way of loading it would be simply
\begin{code}{}
data := DataFrame loadIris.
\end{code}
Now let's take a look at the first and the last 5 entries in our table. These slices are called \textit{head} and \textit{tail} of a data frame.
\begin{code}{}
data head.
data tail.
\end{code}
The output will be the following table
\begin{code}{}
1   (5.1 3.5 1.4 0.2 #setosa)
2	  (4.9 3 1.4 0.2 #setosa)
3	  (4.7 3.2 1.3 0.2 #setosa)
4	  (4.6 3.1 1.5 0.2 #setosa)
5	  (5 3.6 1.4 0.2 #setosa)
\end{code}

\subsection{Univariate non-graphical EDA}
To access a single variable we ask a data frame for a specific column, using its name or number. The result will be a DataSeries object.
\begin{code}{}
series := data column: #sepal_width.
series := data columnAt: 1.
\end{code}
What we can do with a column depends on a type of statistical variable it represents. The best univariate non-graphical EDA for categorical data is a simple tabulation of the frequency of each category\cite{Seltman}. If the data is quantitative, we can ...
\texttt{min, max, range, average, median, mode, stdev, variance}
\begin{code}{}
series average. 
series stdev.
\end{code}

\subsection{Univariate graphical EDA}

The only graphical technique that can be used for a categorical variable is histogram - a barplot where the hight of each bar represents the proportion (count/total count) of cases for a range of values.
Histogram is the only graphical technique that can be used for a categorical variable.

\begin{code}{}
var := data column: #species.
var histogram.
\end{code}

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=0.75\linewidth]{species_bar}
  \end{center}
\end{figure}

\subsection{Multivariate non-graphical EDA}
Multivariate non-graphical EDA shows the relationship between two variables in form of either cross-tabulation (categorical data) or statistics (quantitative data).

\subsection{Multivariate graphical EDA}
\begin{figure}[H]
  \begin{center}
  \includegraphics[width=0.75\linewidth]{boxplot}
  \end{center}
\end{figure}

Let's look at the scatterplot of two statistical variables representing the width and length of a sepal. To do that we ask our DataFrame to give us specific columns, in our case, \texttt{sepal\_width} and \texttt{sepal\_length}, then we ask these columns (the result will be another DataFrame) to visualize themselves.

\begin{code}{}
vars := data columns: #(sepal_width sepal_length).
vars scatterplot.
\end{code}

\begin{figure}[H]
  \begin{center}
  \includegraphics[width=0.75\linewidth]{sepal_wl_scatter}
  \end{center}
\end{figure}

% \section{Discussion}
% \label{sec:discussion}
%
% Discussion of actual solution \emph{vs.} initial constraints from
% \ref{sec:problem}. Explain the space of the solution, why we made it this way.
%
% Evaluation of the solution. How does the solution meet the criteria? Where
% does it succeed or fails...


% \section{Related Works}
% \label{sec:related}
%
% Other solutions in the domain, and a real comparison of our contribution with
% solutions from other people.

\section{Future work}
At the time of writing this paper DataFrame is capable of...
However, a lot of functionality is still missing. For example, we need tools for
\begin{itemize}
  \item data wrangling
  \item data aggregation and grouping
\end{itemize}

\section{Conclusion}
\label{sec:conclusion}

% In this paper, we \textsf{looked}\xspace at problem P with this context and these
% constraints. We proposed solution S. It has such good points and such not so
% good ones. Now we could do this or that.


% \section*{macro example}
%
% \ct{look at it this is code }
% \begin{code}{}
% Class>>nknkjbkjbkjb
%     \{| grgr | 
%     grgrgrgg 
%     a := 
% \end{code}

% \subsection*{Acknowledgements} This work was supported by Ministry of Higher Education and Research, Nord-Pas de Calais Regional Council, FEDER through the 'Contrat de
% Projets Etat Region (CPER) 2007-2013',  the Cutter ANR project, ANR-10-BLAN-0219 and the MEALS Marie Curie Actions program FP7-PEOPLE-2011-
% IRSES MEALS (no. 295261). 

% \bibliographystyle{plain}
% \bibliography{foo.bib}

% \appendix
% 
% \section{Lots of Furry Technical Details}

\bibliographystyle{plain}
\bibliography{pharoeda}

%\bibliography{rmod,others}
\end{multicols}
\end{document}

%%% Local Variables: 
%%% coding: utf-8
%%% mode: latex
%%% TeX-master: "main"
%%% TeX-PDF-mode: t
%%% End:
